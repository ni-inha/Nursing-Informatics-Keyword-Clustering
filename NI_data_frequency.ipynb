{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3967e2c3",
   "metadata": {},
   "source": [
    "# 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb611e9-9b82-4e0e-a2cf-5119e81348d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from inflection import singularize\n",
    "#import inflect\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pandas.core.arrays import StringArray\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc4d85",
   "metadata": {},
   "source": [
    "# 작업이 완료된 년도의 bi/tri/uni 읽고 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530cf472",
   "metadata": {},
   "source": [
    "- 2018년도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced8ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_2018 = pd.read_csv('data/processed_data/ngram_data_frequency_2018.csv') #,encoding='cp949'\n",
    "index = csv_2018['index_1'].dropna()\n",
    "list = []\n",
    "for i in range(len(index)):\n",
    "    if(csv_2018['Flag_1'][i]== 0 and csv_2018['Flag_11'][i]=='X'):\n",
    "        list.append(csv_2018['bigram/trigram'][i])\n",
    "series = pd.Series(list)\n",
    "bi_tri_dict_2018 = series.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069f0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = csv_2018['index_2'].dropna()\n",
    "list = []\n",
    "for i in range(len(index)):\n",
    "    if(csv_2018['Flag_2'][i]== 0 and csv_2018['Flag_22'][i]=='X'):\n",
    "        list.append(csv_2018['unigram'][i])\n",
    "series = pd.Series(list)\n",
    "uni_dict_2018 = series.value_counts().index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb27f9e",
   "metadata": {},
   "source": [
    "- 2021년도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc3b55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_2021 = pd.read_csv('data/processed_data/ngram_data_frequency_2021.csv') #,encoding='cp949'\n",
    "index = csv_2021['index_1'].dropna()\n",
    "list = []\n",
    "for i in range(len(index)):\n",
    "    if(csv_2021['Flag_1'][i]=='X'):\n",
    "        list.append(csv_2021['bigram/trigram'][i])\n",
    "series = pd.Series(list)\n",
    "bi_tri_dict_2021 = series.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e95e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = csv_2021['index_2'].dropna()\n",
    "list = []\n",
    "for i in range(len(index)):\n",
    "    if(csv_2021['Flag_2'][i]=='X'):\n",
    "        list.append(csv_2021['unigram'][i])\n",
    "series = pd.Series(list)\n",
    "uni_dict_2021 = series.value_counts().index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abaf7b",
   "metadata": {},
   "source": [
    "# 작업할 년도의 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9515aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('data/raw_data/datalist_2012.csv',encoding='cp949') #,encoding='cp949'\n",
    "abstract = csv['초록']\n",
    "abstract_val = abstract.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb97b3",
   "metadata": {},
   "source": [
    "- nan 값 제외하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_values = []\n",
    "for i in range(len(abstract_val)):  #nan 값 제외하기\n",
    "  if (abstract_val[i] == abstract_val[i]):\n",
    "    abstract_values.append(abstract_val[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694fdd7",
   "metadata": {},
   "source": [
    "- 특정 문자열 제외하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6736f651-5c20-48ce-900b-e15fa9fae7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_values = []\n",
    "for i in range(len(abstract_values)):\n",
    " final_values.append(re.sub(r'[0-9]',\"\",abstract_values[i])) #https://engineer-mole.tistory.com/238 (문자열에서 특정 문자만 삭제하는 방법)\n",
    "final_val = np.array(final_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21309045",
   "metadata": {},
   "source": [
    "# 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305eea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getList(dict):\n",
    "    list = []\n",
    "    for key in dict.keys():\n",
    "        list.append(key)\n",
    "         \n",
    "    return list\n",
    "#https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/ 딕셔너리를 리스트로 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(list):    \n",
    "    result_list = []\n",
    "    for i in range(len(list)):\n",
    "      new_str = [s.replace(' ','_') for s in list[i]] #https://github.com/RaRe-Technologies/gensim/issues/388 문자열에 whitespace가 있으면 에러가 생김\n",
    "      result_list.append(new_str)\n",
    "        \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22748783-1d1c-41be-a9db-e5cb50528a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nf(list):\n",
    "    new_str = [s.replace(' ','_') for s in list] #https://github.com/RaRe-Technologies/gensim/issues/388 문자열에 whitespace가 있으면 에러가 생김\n",
    "\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aec27c",
   "metadata": {},
   "source": [
    "# ngram  생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f824b51-7470-49e2-9455-bf0013dd46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = stopwords.words('english')\n",
    "c_vec = CountVectorizer(stop_words=stop_word, ngram_range=(2,3)) #https://towardsdatascience.com/text-analysis-basics-in-python-443282942ec5 Text analysis with ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a600c2e-1090-48a7-ae6e-2c976b8701c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = c_vec.fit_transform(final_val)\n",
    "count_values = ngrams.toarray().sum(axis=0)\n",
    "vocab = c_vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3dd1d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15893"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a8d243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = []\n",
    "for i in range(len(final_val)):\n",
    "  sent = []\n",
    "  c_vec.fit_transform([final_val[i].astype('U')]) #여기에서 c_vec에 ngram화된 단어들이 입력됨, U로 유니코드 문자열로 전환해줌\n",
    "  sent.append(c_vec.vocabulary_)\n",
    "  ngrams.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a76211f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(ngrams)):\n",
    "  results.append(getList(ngrams[i][0])) #뒤에 [0]을 붙이면 딕셔너리의 키값이 읽힘 , 리스트에서 문자열로 바뀜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f663610a",
   "metadata": {},
   "source": [
    "# 유의어 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2054e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym = pd.read_csv('data/processed_data/synonym.csv') #,encoding='cp949'\n",
    "original = synonym['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56675375",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(len(results)):\n",
    "    words = results[i]\n",
    "    word_list = []\n",
    "    for word in words:\n",
    "        if(word in original):\n",
    "            word = synonym.loc[synonym['word']==word,'replace']\n",
    "            word_list.append(word)\n",
    "        else:\n",
    "            word_list.append(word)\n",
    "    output.append(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefee2ec",
   "metadata": {},
   "source": [
    "# 이전 년도의 단어 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a0f8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_tri_dict = bi_tri_dict_2018.to_list() + bi_tri_dict_2021.to_list()\n",
    "uni_dict = uni_dict_2018.to_list() + uni_dict_2021.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6bcb0a",
   "metadata": {},
   "source": [
    "- 제거 과정 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79d4e967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 112/112 [00:02<00:00, 54.10it/s]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in tqdm(range(len(output))):\n",
    "    words = output[i]\n",
    "    for word in words:\n",
    "        if(word not in bi_tri_dict and word not in uni_dict):\n",
    "            result.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2ddaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_keyword = []\n",
    "keyword = getList(vocab)\n",
    "for word in keyword:\n",
    "    if word in result:\n",
    "        vocab_keyword.append(word)\n",
    "    else:\n",
    "        del vocab[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce3e84e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15640"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7c102f",
   "metadata": {},
   "source": [
    "# 단어를 df로 변환후 csv에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10067591-d50d-47e9-9018-7ea3ea5bc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_low = []\n",
    "for word in vocab_keyword:\n",
    "    result_low.append(singularize(word))\n",
    "value = vocab.values()\n",
    "vocab1 = dict(zip(result_low, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7c7c9e8-f866-47ec-b913-bd0c33b4569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram = pd.DataFrame(sorted([(count_values[i],k) for k,i in vocab1.items()], reverse=True)).rename(columns={0: 'frequency', 1:'bigram/trigram'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82a855d8-0397-4247-bfa6-ed61a41fee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>bigram/trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>health care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>clinical datum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>nursing documentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>nursing care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>nursing informatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15547</th>\n",
       "      <td>1</td>\n",
       "      <td>ability make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15548</th>\n",
       "      <td>1</td>\n",
       "      <td>ability co ordinated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15549</th>\n",
       "      <td>1</td>\n",
       "      <td>ability co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>1</td>\n",
       "      <td>ability access information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15551</th>\n",
       "      <td>1</td>\n",
       "      <td>ability access</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15552 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequency              bigram/trigram\n",
       "0             20                 health care\n",
       "1             16              clinical datum\n",
       "2             13       nursing documentation\n",
       "3             13                nursing care\n",
       "4             12          nursing informatic\n",
       "...          ...                         ...\n",
       "15547          1                ability make\n",
       "15548          1        ability co ordinated\n",
       "15549          1                  ability co\n",
       "15550          1  ability access information\n",
       "15551          1              ability access\n",
       "\n",
       "[15552 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3afa3210-a8d7-425c-b796-a27eb3fd0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram.to_csv(\"data/processed_data/2012_processed_frequency_bi_tri.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6815e0-15b2-40c7-9cee-b05d75f2166c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_kernel",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
